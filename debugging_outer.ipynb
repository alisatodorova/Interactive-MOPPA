{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import momepy\n",
    "import networkx as nx\n",
    "# import pandas as pd\n",
    "# import shapely\n",
    "# import shapely.geometry as sg\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lmzintgraf_gp_pref_elicit import dataset, gaussian_process, acquisition_function\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_ccs as utils_ccs\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_data as utils_data\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_experiment as utils_experiment\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_parameters as utils_parameters\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_user as utils_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "map = gpd.read_file(\"Sidewalk_width_crossings_smaller.geojson\") #Read in the map with radius 250m and ~1000 nodes\n",
    "\n",
    "# Objectives\n",
    "objective1 = map['length']\n",
    "objective2 = map['crossing']\n",
    "objective3 = map['obstacle_free_width']\n",
    "\n",
    "objectives = ('length', 'crossing')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/test/lib/python3.10/site-packages/momepy/utils.py:252: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf_network[length] = gdf_network.geometry.length\n"
     ]
    }
   ],
   "source": [
    "# Create a NetworkX graph from the map\n",
    "G = momepy.gdf_to_nx(map, approach='primal')\n",
    "nodes = G.nodes\n",
    "# print(len(nodes))\n",
    "edges = G.edges\n",
    "# print(len(max(nx.connected_components(G), key=len)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Show the map as nodes and edges\n",
    "\n",
    "from shapely.geometry import Point\n",
    "# start_node = gpd.GeoDataFrame({'geometry': [Point(122245.37633330293,\n",
    "#                                                   486126.8581684635)]})\n",
    "# end_node = gpd.GeoDataFrame({'geometry': [Point(122247.04588395767,\n",
    "#                                                   486167.91526857053)]})\n",
    "# fig, ax = plt.subplots(figsize=(14,14), dpi=600)\n",
    "# # All nodes and edges\n",
    "# nx.draw(G, {n:[n[0], n[1]] for n in list(G.nodes)}, ax=ax, node_size=3)\n",
    "# # Start & end node\n",
    "# start_node.plot(ax=ax, color='red')\n",
    "# end_node.plot(ax=ax, color='purple')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# print(nodes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Pick random ones or pick manually that make sense - to experiment\n",
    "#Smaller map:\n",
    "S = (122245.37633330293, 486126.8581684635)\n",
    "T = (122246.77932030056, 486223.5791244763)\n",
    "#Small map:\n",
    "# S = (120558.58272730978, 486088.5913559315)\n",
    "# T = (120683.06067979027, 485777.31229122455)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Initialise the Gaussian process for 2 objectives\n",
    "gp = gaussian_process.GPPairwise(num_objectives=2, std_noise=0.01, kernel_width=0.15,prior_mean_type='zero', seed=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "P = [] #Pareto set\n",
    "p = [] #paths computed by Dijkstra's algorithm\n",
    "val_vector_p = [] #value vectors w.r.t. p, i.e., v^{p_1}, v^{p_2}\n",
    "\n",
    "# Path initialisation\n",
    "for i in objectives:\n",
    "    p = nx.shortest_path(G, source=S, target=T, weight=i, method='dijkstra') #Dijkstra's algorithm\n",
    "    P.append(p)\n",
    "\n",
    "    val_obj1 = nx.path_weight(G, path=p, weight='length') #Returns total cost associated with the path and weight. In other words, it returns the value of the path.\n",
    "    val_obj2 = nx.path_weight(G, path=p, weight='crossing')\n",
    "    val_vector_p.append(np.array([val_obj1, val_obj2]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([165.21,   2.  ]), array([227.59,   2.  ])]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vector_p"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([165.21,   2.  ])]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = [min(val_vector_p[0][0], val_vector_p[1][0]), min(val_vector_p[0][1], val_vector_p[1][1])] #Candidate Targets, i.e., the most optimistic points\n",
    "C = [np.array(C)]\n",
    "C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# User ranking: Compare paths in P\n",
    "user_preference = utils_user.UserPreference(num_objectives=2, std_noise=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232245.90127472 232246.13591216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alisatodorova/Desktop/Thesis/Interactive-MOPPA/lmzintgraf_gp_pref_elicit/gp_utilities/utils_user.py:254: RuntimeWarning: overflow encountered in exp\n",
      "  y += 1. / (1 + np.exp(- x * (a-i) + (b+i)))\n"
     ]
    }
   ],
   "source": [
    "add_noise = True\n",
    "ground_utility = user_preference.get_preference(val_vector_p, add_noise=add_noise) #This is the ground-truth utility, i.e., the true utility\n",
    "print(ground_utility)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227.59   2.  ]\n",
      " [165.21   2.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Add the comparisons to GP\n",
    "comparisons = dataset.DatasetPairwise(num_objectives=2)\n",
    "\n",
    "comparisons.add_single_comparison(val_vector_p[np.argmax(ground_utility)], val_vector_p[np.argmin(ground_utility)]) #This way we are performing user ranking of their preferences\n",
    "print(comparisons.datapoints)\n",
    "gp.update(comparisons)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02560537  0.02560537]\n"
     ]
    }
   ],
   "source": [
    "# Find the path the user likes best and has the maximum a posteriori (MAP) estimate\n",
    "u_v, _ = gp.get_predictive_params(val_vector_p, True) #The maximum a posteriori (MAP) estimate is the mean from gaussian_process.get_predictive_params()\n",
    "print(u_v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_star_index = np.argmax(u_v)\n",
    "p_star_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[(122245.37633330293, 486126.8581684635),\n (122254.86602688645, 486129.80052856216),\n (122264.35426393585, 486132.74411788705),\n (122273.84081337851, 486135.69101398275),\n (122283.19823912054, 486138.9678026403),\n (122284.1816391946, 486139.19731384714),\n (122287.28805009159, 486137.97386694513),\n (122291.40829399273, 486140.643590483),\n (122297.7854183222, 486139.47700177913),\n (122332.49987764945, 486160.7773385103),\n (122328.7127865793, 486160.19348477497),\n (122324.68334361241, 486169.2581765358),\n (122320.97320132754, 486178.5199137332),\n (122319.70610252809, 486181.6875618371),\n (122286.01308887315, 486183.8814735307),\n (122282.69556966702, 486193.2948693236),\n (122279.36739295325, 486202.70485648955),\n (122276.034562429, 486212.11332275654),\n (122274.00277185065, 486217.2508821529),\n (122271.878266905, 486221.2167929504),\n (122262.38569380266, 486218.13414513733),\n (122254.26477155345, 486215.7695028797),\n (122253.09793657108, 486219.18429932056),\n (122246.77932030056, 486223.5791244763)]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_star = P[p_star_index]\n",
    "p_star"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165.21   2.  ]]\n"
     ]
    }
   ],
   "source": [
    "input_domain = np.array(C) #set of candidate targets\n",
    "print(input_domain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Initialise the acquisition function\n",
    "acq_fun = acquisition_function.DiscreteAcquirer(input_domain=input_domain, query_type='ranking', seed=123, acquisition_type='expected improvement')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# TODO: The next code cells are in a while-loop\n",
    "# while C:\n",
    "#     expected_improvement = acquisition_function.get_expected_improvement(input_domain, gp, acq_fun.history)\n",
    "#     t_index = np.argmax(expected_improvement)\n",
    "#     t = C[t_index]\n",
    "#     C.remove(t)\n",
    "#\n",
    "# # t_index\n",
    "# print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12047789]\n"
     ]
    }
   ],
   "source": [
    "expected_improvement = acquisition_function.get_expected_improvement(input_domain, gp, acq_fun.history)\n",
    "print(expected_improvement)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_index = np.argmax(expected_improvement)\n",
    "t_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.21   2.  ]\n"
     ]
    }
   ],
   "source": [
    "t = input_domain[t_index]\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "# Remove t from C\n",
    "C = np.delete(C, np.where(np.all(C == t)))\n",
    "print(C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v_n = {}\n",
    "threshold=1e-8\n",
    "max_iter=1000\n",
    "obj = 'length'\n",
    "next_node = {}\n",
    "\n",
    "for n in G:\n",
    "    v_n[n] = np.inf\n",
    "    if n == T:\n",
    "        v_n[n] = 0\n",
    "\n",
    "for i in range(max_iter): #or until convergence\n",
    "\n",
    "    converged = True\n",
    "\n",
    "    # print(\"iteration:\", i)\n",
    "    for e in G.edges(data=True):\n",
    "        n1, n2 = e[0], e[1]\n",
    "        # if v_n[n1] != np.inf or v_n[n2] != np.inf:\n",
    "        #     print(e[0], e[1], \":\", v_n[n1], v_n[n2])\n",
    "\n",
    "        # print(n2 in G)\n",
    "        cost = e[2][obj]\n",
    "            # print(cost)\n",
    "\n",
    "            # print(e)\n",
    "        result1 = min(cost + v_n[n2], v_n[n1])\n",
    "        result2 = min(cost + v_n[n1], v_n[n2])\n",
    "            # print(\"result1:\", result1, \"sum1:\", cost + v_n[n2])\n",
    "            # print(\"result2\", result2, \"sum2:\", cost + v_n[n1])\n",
    "        if v_n[n1] != result1 or v_n[n2] != result2:\n",
    "            converged = False\n",
    "\n",
    "        if v_n[n1] != result1:\n",
    "            next_node[n1] = n2\n",
    "\n",
    "        if v_n[n2] != result2:\n",
    "            next_node[n2] = n1\n",
    "\n",
    "        v_n[n1] = result1\n",
    "        v_n[n2] = result2\n",
    "\n",
    "        # if n1 == T or n2==T:\n",
    "        #     # print(result1, result2)\n",
    "        #     print(v_n[n1], v_n[n2])\n",
    "\n",
    "\n",
    "    # converged = all(n in v_n_copy and abs(v_n[n] - v_n_copy[n]) < threshold for n in v_n)\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "        # if v_n[n1] != np.inf:\n",
    "        #     print(n1,v_n[n1])\n",
    "        # if v_n[n2] != np.inf:\n",
    "        #     print(n2,v_n[n2])\n",
    "\n",
    "print(v_n)\n",
    "print(next_node)\n",
    "# import single_vi_iter\n",
    "# lower_bounds = single_vi_iter.single_value_iter(G)\n",
    "lower_bounds = v_n\n",
    "\n",
    "# lower_bounds = dict(sorted(lower_bounds.items(), key=lambda x: lower_bounds[x[0]],\n",
    "#                        reverse=True))\n",
    "#\n",
    "# lower_bounds\n",
    "\n",
    "# S = (122245.37633330293, 486126.8581684635)\n",
    "# T = (122246.77932030056, 486223.5791244763)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: Fix this\n",
    "i = 0  # track iterations of the algorithm\n",
    "max_iter=1000\n",
    "\n",
    "stack = [(S, 0, [S])]  # (starting node, cost, path), where cost is from previous_state to S, path is from S to current_state (i.e., S)\n",
    "\n",
    "obj = 'length'\n",
    "\n",
    "while stack:\n",
    "    current_node, cost, path = stack.pop()  # cost=total cost up to the current_node\n",
    "\n",
    "    if current_node == T:\n",
    "        print(f\"Path {path} with cost {cost}\")\n",
    "    #\n",
    "    # for e in G.edges(data=True):\n",
    "    #     n1, n2 = e[0], e[1]\n",
    "    #     cost = e[2][obj]\n",
    "    #     total_cost = cost + next_node_cost\n",
    "    for next_node in G[current_node]:\n",
    "        for key in G:\n",
    "            total_cost = key + next_node\n",
    "            new_path = path + [next_node] # Add the neighbor to the path\n",
    "        # print(new_path)\n",
    "        stack.append((next_node, total_cost, new_path))\n",
    "        # print(stack)\n",
    "        stack.sort(key=lambda x: lower_bounds[x[0]],\n",
    "                       reverse=True)  # Sorts in descending order w.r.t. the lower bound\n",
    "\n",
    "    i += 1\n",
    "    if max_iter is not None and i >= max_iter:\n",
    "        print(path)\n",
    "        print(\"The algorithm has reached the given maximum iterations, but has found no solution.\")\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"The algorithm has terminated, but no solution was found.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inner-loop approach\n",
    "import dfs_lower\n",
    "p_s = dfs_lower.dfs_lower(G, S, t, lower_bounds)\n",
    "print(p_s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: Line 15 of pseudocode is unclear to me how it should be in code.\n",
    "# If v^p improves in the target region\n",
    "# because you've identified a new value vector on the PCS. If you stop once the utility no longer improves, I think this can result in stopping prematurely. Specifically, imagine you have a current partial Pareto front of (10,0) and (0,10) the user model u((10,0)) is the current best. The target vector is (10,10)  and when you run DFS, you get one of the possible vectors in the target region. You get (1,9) out of the the call to DFS, and the u((1,9)) < u((10,0)) even after querying the user about it. Now here, you shouldn't stop, because the true best - (7,3) for example, is still possible to find.\n",
    "#you're just not going to improve on that with a newly found vector\n",
    "#So improving on the acquisition function by identifying a new point is impossible as\n",
    "# 1) you were searching at an optimistic estimate (target), so the actually found value will be worse than the target\n",
    "# 2) finding new points, and querying the user reduces uncertainty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P = P.append(p_s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: Can't test because of p_s (see above)\n",
    "#Compare p^s to p^∗ and add comparison to the GP ▷User ranking, i.e., is the new path preferred to the current, maximum one?\n",
    "\n",
    "val_vector_new_paths = [] #value vectors of paths p^s and p^∗\n",
    "\n",
    "for i in objectives:\n",
    "    val_p_s = nx.path_weight(G, path=p_s, weight=i)\n",
    "    val_p_star = nx.path_weight(G, path=p_star, weight=i)\n",
    "\n",
    "    val_vector_new_paths.append(np.array([val_p_s, val_p_star]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranking_new_paths = user_preference.get_preference(val_vector_new_paths, add_noise=add_noise)\n",
    "print(ranking_new_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add the comparisons to GP\n",
    "comparisons.add_single_comparison(val_vector_new_paths[np.argmax(ranking_new_paths)], val_vector_new_paths[\n",
    "    np.argmin(ranking_new_paths)])  #This way we are performing user ranking of their preferences\n",
    "print(comparisons.datapoints)\n",
    "gp.update(comparisons)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u_v_p_s, _ = gp.get_predictive_params(val_p_s, True)  #The maximum a posteriori (MAP) estimate is the mean from gaussian_process.get_predictive_params()\n",
    "u_v_p_star, _ = gp.get_predictive_params(val_p_star, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if u(v^{p^s}) > u(v^{p^*}) then\n",
    "if u_v_p_s > u_v_p_star:\n",
    "    #p^∗ ← p^s\n",
    "    p_star = p_s\n",
    "# end if"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compute new candidate targets based on v^{p^s} and add to C\n",
    "C = [min(val_p_s[0][0], val_p_s[1][0]), min(val_p_s[0][1], val_p_s[1][1])]\n",
    "C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# end if\n",
    "# end while\n",
    "# return p^∗, v^{p^*}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
