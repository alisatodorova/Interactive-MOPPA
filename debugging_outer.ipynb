{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import momepy\n",
    "import networkx as nx\n",
    "# import pandas as pd\n",
    "# import shapely\n",
    "# import shapely.geometry as sg\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lmzintgraf_gp_pref_elicit import dataset, gaussian_process, acquisition_function\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_ccs as utils_ccs\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_data as utils_data\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_experiment as utils_experiment\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_parameters as utils_parameters\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_user as utils_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map = gpd.read_file(\"Sidewalk_width_crossings_smaller.geojson\") #~180 nodes\n",
    "\n",
    "# Objectives\n",
    "objective1 = map['length']\n",
    "objective2 = map['crossing']\n",
    "objective3 = map['obstacle_free_width']\n",
    "\n",
    "objectives = ('length', 'crossing')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a NetworkX graph from the map\n",
    "G = momepy.gdf_to_nx(map, approach='primal')\n",
    "nodes = G.nodes\n",
    "# print(len(nodes))\n",
    "edges = G.edges\n",
    "# print(len(max(nx.connected_components(G), key=len)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Show the map as nodes and edges\n",
    "\n",
    "from shapely.geometry import Point\n",
    "# start_node = gpd.GeoDataFrame({'geometry': [Point(122245.37633330293,\n",
    "#                                                   486126.8581684635)]})\n",
    "# end_node = gpd.GeoDataFrame({'geometry': [Point(122247.04588395767,\n",
    "#                                                   486167.91526857053)]})\n",
    "# fig, ax = plt.subplots(figsize=(14,14), dpi=600)\n",
    "# # All nodes and edges\n",
    "# nx.draw(G, {n:[n[0], n[1]] for n in list(G.nodes)}, ax=ax, node_size=3)\n",
    "# # Start & end node\n",
    "# start_node.plot(ax=ax, color='red')\n",
    "# end_node.plot(ax=ax, color='purple')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(nodes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Pick random ones or pick manually that make sense - to experiment\n",
    "#Smaller map:\n",
    "S = (122245.37633330293, 486126.8581684635)\n",
    "T = (122246.77932030056, 486223.5791244763)\n",
    "#Small map:\n",
    "# S = (120558.58272730978, 486088.5913559315)\n",
    "# T = (120683.06067979027, 485777.31229122455)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import inner_loop, outer_loop\n",
    "p_star, val_vector_p_star = outer_loop.outer(G, S, T, objectives)\n",
    "print(f\"Path {p_star} with cost {val_vector_p_star}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialise the Gaussian process for 2 objectives\n",
    "gp = gaussian_process.GPPairwise(num_objectives=2, std_noise=0.01, kernel_width=0.15,prior_mean_type='zero', seed=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "P = [] #Pareto set\n",
    "p = [] #paths computed by Dijkstra's algorithm\n",
    "val_vector_p = [] #value vectors w.r.t. p, i.e., v^{p_1}, v^{p_2}\n",
    "\n",
    "# Path initialisation\n",
    "for i in objectives:\n",
    "    p = nx.shortest_path(G, source=S, target=T, weight=i, method='dijkstra') #Dijkstra's algorithm\n",
    "    P.append(p)\n",
    "\n",
    "    val_obj1 = nx.path_weight(G, path=p, weight='length') #Returns total cost associated with the path and weight. In other words, it returns the value of the path.\n",
    "    val_obj2 = nx.path_weight(G, path=p, weight='crossing')\n",
    "    val_vector_p.append(np.array([val_obj1, val_obj2]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_vector_p"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Candidate Targets, i.e., the most optimistic points\n",
    "C = [min(val_vector_p[0][0], val_vector_p[1][0]), min(val_vector_p[0][1], val_vector_p[1][1])]\n",
    "C = [np.array(C)]\n",
    "C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The most pessimistic points form the upper bounds\n",
    "U = [max(val_vector_p[0][0], val_vector_p[1][0]), max(val_vector_p[0][1], val_vector_p[1][1])]\n",
    "U"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# User ranking: Compare paths in P\n",
    "user_preference = utils_user.UserPreference(num_objectives=2, std_noise=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_noise = True\n",
    "ground_utility = user_preference.get_preference(val_vector_p, add_noise=add_noise) #This is the ground-truth utility, i.e., the true utility\n",
    "print(ground_utility)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add the comparisons to GP\n",
    "comparisons = dataset.DatasetPairwise(num_objectives=2)\n",
    "\n",
    "comparisons.add_single_comparison(val_vector_p[np.argmax(ground_utility)], val_vector_p[np.argmin(ground_utility)]) #This way we are performing user ranking of their preferences\n",
    "print(comparisons.datapoints)\n",
    "gp.update(comparisons)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the path the user likes best and has the maximum a posteriori (MAP) estimate\n",
    "u_v, _ = gp.get_predictive_params(val_vector_p, True) #The maximum a posteriori (MAP) estimate is the mean from gaussian_process.get_predictive_params()\n",
    "print(u_v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_star_index = np.argmax(u_v)\n",
    "p_star_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_star = P[p_star_index]\n",
    "p_star"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_domain = np.array(C) #set of candidate targets\n",
    "print(input_domain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialise the acquisition function\n",
    "acq_fun = acquisition_function.DiscreteAcquirer(input_domain=input_domain, query_type='ranking', seed=123, acquisition_type='expected improvement')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: The next code cells are in a while-loop\n",
    "# while C:\n",
    "#     expected_improvement = acquisition_function.get_expected_improvement(input_domain, gp, acq_fun.history)\n",
    "#     t_index = np.argmax(expected_improvement)\n",
    "#     t = C[t_index]\n",
    "#     C.remove(t)\n",
    "#\n",
    "# # t_index\n",
    "# print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expected_improvement = acquisition_function.get_expected_improvement(input_domain, gp, acq_fun.history)\n",
    "print(expected_improvement)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_index = np.argmax(expected_improvement)\n",
    "t_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = input_domain[t_index]\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove t from C\n",
    "C = np.delete(C, np.where(np.all(C == t)))\n",
    "print(C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v_n = {}\n",
    "threshold=1e-8\n",
    "max_iter=1000\n",
    "obj = 'length'\n",
    "next_node = {}\n",
    "edge_cost = []\n",
    "\n",
    "for n in G:\n",
    "    v_n[n] = np.inf\n",
    "    if n == T:\n",
    "        v_n[n] = 0\n",
    "\n",
    "for i in range(max_iter): #or until convergence\n",
    "\n",
    "    converged = True\n",
    "\n",
    "    # print(\"iteration:\", i)\n",
    "    for e in G.edges(data=True):\n",
    "        n1, n2 = e[0], e[1]\n",
    "        # if v_n[n1] != np.inf or v_n[n2] != np.inf:\n",
    "        #     print(e[0], e[1], \":\", v_n[n1], v_n[n2])\n",
    "\n",
    "        # print(n2 in G)\n",
    "        cost = e[2][obj]\n",
    "        edge_cost.append(cost)\n",
    "        # print(cost)\n",
    "\n",
    "            # print(e)\n",
    "        result1 = min(cost + v_n[n2], v_n[n1])\n",
    "        result2 = min(cost + v_n[n1], v_n[n2])\n",
    "            # print(\"result1:\", result1, \"sum1:\", cost + v_n[n2])\n",
    "            # print(\"result2\", result2, \"sum2:\", cost + v_n[n1])\n",
    "        if v_n[n1] != result1 or v_n[n2] != result2:\n",
    "            converged = False\n",
    "\n",
    "        if v_n[n1] != result1:\n",
    "            next_node[n1] = n2\n",
    "\n",
    "        if v_n[n2] != result2:\n",
    "            next_node[n2] = n1\n",
    "\n",
    "        v_n[n1] = result1\n",
    "        v_n[n2] = result2\n",
    "\n",
    "        # if n1 == T or n2==T:\n",
    "        #     # print(result1, result2)\n",
    "        #     print(v_n[n1], v_n[n2])\n",
    "\n",
    "\n",
    "    # converged = all(n in v_n_copy and abs(v_n[n] - v_n_copy[n]) < threshold for n in v_n)\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "\n",
    "        # if v_n[n1] != np.inf:\n",
    "        #     print(n1,v_n[n1])\n",
    "        # if v_n[n2] != np.inf:\n",
    "        #     print(n2,v_n[n2])\n",
    "\n",
    "print(v_n)\n",
    "# print(next_node)\n",
    "\n",
    "# S = (122245.37633330293, 486126.8581684635)\n",
    "# T = (122246.77932030056, 486223.5791244763)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import single_vi_iter\n",
    "# lower_bounds = []\n",
    "# next_nodes = []\n",
    "\n",
    "lower_length = single_vi_iter.single_value_iter(G, T, 'length')\n",
    "lower_crossing = single_vi_iter.single_value_iter(G, T, 'crossing')\n",
    "# next_nodes.append(np.array([next_node_length, next_node_crossing]))\n",
    "# print(\"NEXT:\", next_node_crossing)\n",
    "\n",
    "# lower_bounds.append(np.array([lower_length, lower_crossing]))\n",
    "# lower_bounds\n",
    "\n",
    "#crossing: (122246.10058319086, 486224.512771215): (122246.77932030056, 486223.5791244763)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def cost_to(current_node, obj): # Cost from S to current_node for 1 objective\n",
    "#     total_cost = 0\n",
    "#\n",
    "#     for e in G.edges(data=True):\n",
    "#         # print(e[0])\n",
    "#         edge_cost = e[2][obj]\n",
    "#\n",
    "#         if e[0] == current_node or e[1] == current_node:\n",
    "#             break\n",
    "#\n",
    "#         total_cost += edge_cost\n",
    "#     return total_cost\n",
    "#\n",
    "# cost_both_obj = []\n",
    "# current_n = (122284.1816391946, 486139.19731384714)\n",
    "# obj1 = cost_to(current_n, 'length')\n",
    "# obj2 = cost_to(current_n, 'crossing')\n",
    "# cost_both_obj.append(np.array([obj1, obj2]))\n",
    "# print(cost_both_obj)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0  # track iterations of the algorithm\n",
    "max_iter = 1000\n",
    "\n",
    "cost_history = np.array([0,0]) # What we've already seen\n",
    "\n",
    "stack = [(S, cost_history, [S])]  # (starting node, cost so far, path), where cost_history is from previous_state to S, path is from S to current_state (i.e., S)\n",
    "\n",
    "# r1 = 0 # Result from objective length\n",
    "# r2 = 0 # Result from objective crossing\n",
    "result = [] # The new lower bound\n",
    "\n",
    "# min_distance = np.inf\n",
    "# closest_node = None\n",
    "# val_vector_path = []\n",
    "\n",
    "\n",
    "while stack:\n",
    "    current_node, current_cost, path = stack.pop()  # current_cost=total cost up to the current_node\n",
    "\n",
    "    if current_node == T:\n",
    "        U = current_cost\n",
    "        print(f\"Path {path} with cost {current_cost}\")\n",
    "\n",
    "    neighbor_list = []\n",
    "\n",
    "    for neighbor in G.neighbors(current_node):\n",
    "        edge = G[current_node][neighbor]\n",
    "        list = [v for k, v in edge.items()]\n",
    "        # print(edge)\n",
    "        cost = np.array([list[0]['length'], list[0]['crossing']])\n",
    "\n",
    "        result = current_cost + cost + np.array([lower_length[neighbor], lower_crossing[neighbor]]) # This is the new lower bound\n",
    "        # print(result)\n",
    "\n",
    "        # Pruning paths that won't be Pareto-better compared to the current upper bound\n",
    "        if np.any(np.greater(result, U)): # If it's outside of target region, ignore it\n",
    "            continue\n",
    "\n",
    "        distance = np.sum(np.abs(t - result)) # Manhattan distance\n",
    "\n",
    "        neighbor_list.append((neighbor, distance, (current_cost + cost)))\n",
    "\n",
    "\n",
    "    neighbor_list.sort(key=lambda x:x[1], reverse=True)\n",
    "    for n in neighbor_list:\n",
    "        path_copy = path.copy()\n",
    "        path_copy.append(n[0])\n",
    "        stack.append((n[0], n[2], path_copy))\n",
    "\n",
    "    i += 1\n",
    "    if max_iter is not None and i >= max_iter:\n",
    "        print(\"The algorithm has reached the given maximum iterations, but has found no solution.\")\n",
    "        break\n",
    "\n",
    "# S = (122245.37633330293, 486126.8581684635)\n",
    "# T = (122246.77932030056, 486223.5791244763)\n",
    "# t = [165.21   2.  ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_s = path\n",
    "# Inner-loop approach\n",
    "# import dfs_lower\n",
    "# p_s = dfs_lower.dfs_lower(G, S, t, lower_bounds)\n",
    "# print(p_s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If v^p_s improves in the target region\n",
    "\n",
    "# val_vector_p_s = []\n",
    "# val_p_s1 = nx.path_weight(G, path=p_s, weight='length')\n",
    "# val_p_s2 = nx.path_weight(G, path=p_s, weight='crossing')\n",
    "# val_vector_p_s.append(np.array([val_p_s1, val_p_s2]))\n",
    "# if val_p_s1 < U[0] and val_p_s2 < U[1]:\n",
    "if np.any(np.greater(current_cost, U)):\n",
    "    P = P.append(p_s)\n",
    "\n",
    "    #Compare p^s to p^∗ and add comparison to the GP ▷User ranking, i.e., is the new path preferred to the current, maximum one?\n",
    "    compare_ps_pstar = []\n",
    "    val_vector_p_star = []\n",
    "\n",
    "    val_p_star1 = nx.path_weight(G, path=p_star, weight='length')\n",
    "    val_p_star2 = nx.path_weight(G, path=p_star, weight='crossing')\n",
    "    val_vector_p_star.append(np.array([val_p_star1, val_p_star2]))\n",
    "\n",
    "    compare_ps_pstar.append(np.array([current_cost, val_vector_p_star]))\n",
    "\n",
    "    ranking_new_paths = user_preference.get_preference(compare_ps_pstar, add_noise=add_noise)\n",
    "    print(ranking_new_paths)\n",
    "\n",
    "    # Add the comparisons to GP\n",
    "    comparisons.add_single_comparison(compare_ps_pstar[np.argmax(ranking_new_paths)], compare_ps_pstar[np.argmin(ranking_new_paths)])  #This way we are performing user ranking of their preferences\n",
    "    # print(comparisons.datapoints)\n",
    "    gp.update(comparisons)\n",
    "\n",
    "    u_v_p_s, _ = gp.get_predictive_params(current_cost, True)  #The maximum a posteriori (MAP) estimate is the mean from gaussian_process.get_predictive_params()\n",
    "    u_v_p_star, _ = gp.get_predictive_params(val_vector_p_star, True)\n",
    "\n",
    "    # if u(v^{p^s}) > u(v^{p^*}) then\n",
    "    if current_cost > val_vector_p_star:\n",
    "        #p^∗ ← p^s\n",
    "        p_star = p_s\n",
    "\n",
    "    # Compute new candidate targets based on v^{p^s} and add to C\n",
    "    new_C = [min(current_cost[0][0], current_cost[1][0]), min(current_cost[0][1], current_cost[1][1])]\n",
    "    C = np.append(new_C)\n",
    "print(f\"P_star: {p_star} with cost {val_vector_p_star}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
