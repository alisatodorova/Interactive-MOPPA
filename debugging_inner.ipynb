{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import momepy\n",
    "import time\n",
    "import copy\n",
    "import networkx as nx\n",
    "# import pandas as pd\n",
    "# import shapely\n",
    "# import shapely.geometry as sg\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "from lmzintgraf_gp_pref_elicit import dataset, gaussian_process, acquisition_function\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_ccs as utils_ccs\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_data as utils_data\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_experiment as utils_experiment\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_parameters as utils_parameters\n",
    "from lmzintgraf_gp_pref_elicit.gp_utilities import utils_user as utils_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "map_amsterdam = gpd.read_file(\"Sidewalk_width_crossings_smaller.geojson\") #Read in the map with radius 250m and ~1000 nodes\n",
    "\n",
    "# Objectives\n",
    "objective1 = map_amsterdam['length']\n",
    "objective2 = map_amsterdam['crossing']\n",
    "objective3 = map_amsterdam['obstacle_free_width']\n",
    "\n",
    "objectives = ('length', 'crossing')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/test/lib/python3.10/site-packages/momepy/utils.py:252: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf_network[length] = gdf_network.geometry.length\n"
     ]
    }
   ],
   "source": [
    "# Create a NetworkX graph from the map\n",
    "G = momepy.gdf_to_nx(map_amsterdam, approach='primal')\n",
    "nodes = G.nodes\n",
    "edges = G.edges\n",
    "# print(G)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# print(nodes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Pick random ones or pick manually that make sense - to experiment\n",
    "S = (122245.37633330293, 486126.8581684635) #very first node\n",
    "# T = (122320.31466476223, 486327.5294561802)\n",
    "T = (122253.09793657108, 486219.18429932056)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds elapsed: 71.77672982215881\n"
     ]
    }
   ],
   "source": [
    "def pareto_dominates(a, b):\n",
    "    \"\"\"Check if the vector in b Pareto dominates vector a.\n",
    "\n",
    "    Note: The original code has been modified to work for our minimization problem.\n",
    "\n",
    "    Args:\n",
    "        a (ndarray): A numpy array.\n",
    "        b (ndarray): A numpy array.\n",
    "\n",
    "    Returns:\n",
    "        bool: Whether vector b dominates vector a.\n",
    "    \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.all(a <= b) and np.any(a < b)\n",
    "\n",
    "\n",
    "def p_prune(candidates):\n",
    "    \"\"\"Create a Pareto coverage set from a set of candidate points.\n",
    "\n",
    "    References:\n",
    "        .. [1] Roijers, D. M., & Whiteson, S. (2017). Multi-objective decision making. 34, 129â€“129.\n",
    "            https://doi.org/10.2200/S00765ED1V01Y201704AIM034\n",
    "\n",
    "    Args:\n",
    "        candidates (Set[Tuple]): A set of vectors.\n",
    "\n",
    "    Returns:\n",
    "        Set[Tuple]: A Pareto coverage set.\n",
    "    \"\"\"\n",
    "    pcs = set()\n",
    "    while candidates:\n",
    "        vector = candidates.pop()\n",
    "\n",
    "        for alternative in candidates:\n",
    "            if pareto_dominates(alternative, vector):\n",
    "                vector = alternative\n",
    "\n",
    "        to_remove = set(vector)\n",
    "        for alternative in candidates:\n",
    "            if pareto_dominates(vector, alternative):\n",
    "                to_remove.add(alternative)\n",
    "\n",
    "        candidates -= to_remove\n",
    "        pcs.add(vector)\n",
    "    return pcs\n",
    "\n",
    "\n",
    "def pvi(G, T, objectives, max_iter=100):\n",
    "    start = time.time()\n",
    "    nd_vectors = [[{tuple(np.full(2, np.inf))} for _ in range(len(G.nodes))] for _ in range(len(G.nodes))] # Initialisation of nodes\n",
    "    is_last = False\n",
    "\n",
    "    path = []\n",
    "\n",
    "    for n, current_node in enumerate(G.nodes):\n",
    "        if current_node == T:  # We've reached the terminal state\n",
    "            nd_vectors[n] = [{(0, 0)} for _ in G.nodes]\n",
    "\n",
    "    nd_vectors_update = copy.deepcopy(nd_vectors)\n",
    "    for run in range(max_iter):  # We execute the algorithm for a number of iterations.\n",
    "        # print(f'Value Iteration number: {run}')\n",
    "        for n, current_node in enumerate(G.nodes):  # Loop over all states. Note: current_node is an object; n=number\n",
    "            if current_node == T:\n",
    "                continue\n",
    "\n",
    "            for nk, neighbor in enumerate(G.nodes): #Note: neighbor is an object; k=number\n",
    "                if neighbor not in G.neighbors(current_node):\n",
    "                    continue\n",
    "\n",
    "                edge = G[current_node][neighbor]\n",
    "                edge_list = [v for k, v in edge.items()]  # Stores only the values of the edges' properties\n",
    "\n",
    "                cost = []\n",
    "                for i in objectives:\n",
    "                  cost.append(edge_list[0][i])\n",
    "\n",
    "                cost = np.array(cost)\n",
    "                results = set()\n",
    "\n",
    "                for v_list in nd_vectors[nk]:\n",
    "                    for value_vec in v_list:\n",
    "                        results.add(tuple(cost+value_vec)) # The set of candidate vectors\n",
    "\n",
    "                results = p_prune(results)\n",
    "\n",
    "                nd_vectors_update[n][nk] = results\n",
    "\n",
    "                if nd_vectors_update[n][nk] == {(157.33,2.)}:\n",
    "                    path.append(current_node)\n",
    "                    current_node = neighbor\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if is_last:\n",
    "            break\n",
    "        nd_vectors = copy.deepcopy(nd_vectors_update)  # Else perform a deep copy and go again.\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_seconds = (end - start)\n",
    "    print(\"Seconds elapsed: \" + str(elapsed_seconds))\n",
    "\n",
    "    return nd_vectors_update\n",
    "\n",
    "\n",
    "\n",
    "pvi_result = pvi(G, T, objectives)\n",
    "# print(pvi_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 64\u001B[0m\n\u001B[1;32m     56\u001B[0m             \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     57\u001B[0m             \u001B[38;5;66;03m# if current_node == T:\u001B[39;00m\n\u001B[1;32m     58\u001B[0m             \u001B[38;5;66;03m#     terminated = True\u001B[39;00m\n\u001B[1;32m     59\u001B[0m             \u001B[38;5;66;03m#     truncated = True\u001B[39;00m\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m reward\n\u001B[0;32m---> 64\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mtrack_policy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m157.33\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2.\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpvi_result\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mprint\u001B[39m(res)\n",
      "Cell \u001B[0;32mIn[14], line 37\u001B[0m, in \u001B[0;36mtrack_policy\u001B[0;34m(G, T, target, pvi_vec, tol)\u001B[0m\n\u001B[1;32m     35\u001B[0m q \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(q)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# print(f\"q:{q}\")\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m dist \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mim_rew\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# print(f\"distance:{dist}\")\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dist \u001B[38;5;241m<\u001B[39m closest_dist:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# for each action in A:\n",
    "# retireve R=cost\n",
    "# Q is set of value vector\n",
    "# s' is neighbor\n",
    "# T is 1\n",
    "# actions = neighbors\n",
    "\n",
    "\n",
    "def track_policy(G, T, target, pvi_vec, tol=1e-3):\n",
    "        \"\"\"Track a policy from its return vector.\n",
    "\n",
    "        Args:\n",
    "            G: Graph\n",
    "            tol (float, optional): The tolerance for the return vector. (Default value = 1e-3)\n",
    "        \"\"\"\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        total_rew = np.zeros(2)\n",
    "\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            closest_dist = np.inf\n",
    "            closest_action = 0\n",
    "            found_action = False\n",
    "            new_target = target\n",
    "\n",
    "            for n, current_node in enumerate(G.nodes):\n",
    "                for nk, neighbor in enumerate(G.neighbors(current_node)):\n",
    "                    im_rew = [n, nk]\n",
    "                    # print(f\"im_rew:{im_rew}\")\n",
    "                    non_dominated_set = pvi_vec[n][nk]\n",
    "                    # print(f\"non_dominated set:{non_dominated_set}\")\n",
    "\n",
    "                    for q in non_dominated_set:\n",
    "                        q = np.array(q)\n",
    "                        # print(f\"q:{q}\")\n",
    "                        dist = np.sum(np.abs(q + im_rew - target))\n",
    "                        # print(f\"distance:{dist}\")\n",
    "                        if dist < closest_dist:\n",
    "                            closest_dist = dist\n",
    "                            closest_action = nk\n",
    "                            new_target = q\n",
    "\n",
    "                            if dist < tol:\n",
    "                                found_action = True\n",
    "                                break\n",
    "\n",
    "                    if found_action:\n",
    "                        break\n",
    "\n",
    "                #closest action = edge you want to take\n",
    "                #step = go to neighbor node\n",
    "                n = closest_action\n",
    "                reward = im_rew\n",
    "                target = new_target\n",
    "            #\n",
    "            # if current_node == T:\n",
    "            #     terminated = True\n",
    "            #     truncated = True\n",
    "\n",
    "\n",
    "        return reward\n",
    "\n",
    "res = track_policy(G, T, (157.33,2.), pvi_result)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def track_policy():\n",
    "#         \"\"\"Track a policy from its return vector.\n",
    "#\n",
    "#         Args:\n",
    "#             vec (array_like): The return vector to track.\n",
    "#             G: Graph\n",
    "#             tol (float, optional): The tolerance for the return vector. (Default value = 1e-3)\n",
    "#         \"\"\"\n",
    "#         # target = np.array(vec)\n",
    "#         # state, _ = env.reset()\n",
    "#         terminated = False\n",
    "#         truncated = False\n",
    "#         total_rew = np.zeros(self.num_objectives)\n",
    "#\n",
    "#         while not (terminated or truncated):\n",
    "#             # state = np.ravel_multi_index(state, self.env_shape)\n",
    "#             closest_dist = np.inf\n",
    "#             closest_action = 0\n",
    "#             found_action = False\n",
    "#             new_target = target\n",
    "#\n",
    "#             for n, current_node in enumerate(G.nodes):\n",
    "#                 for nk, neighbor in enumerate(G.neighbors(current_node)):\n",
    "#                     im_rew = self.avg_reward[n, nk]\n",
    "#                     non_dominated_set = self.non_dominated[n][nk]\n",
    "#\n",
    "#                     for q in non_dominated_set:\n",
    "#                         q = np.array(q)\n",
    "#                         dist = np.sum(np.abs(q + im_rew - t))\n",
    "#                         if dist < closest_dist:\n",
    "#                             closest_dist = dist\n",
    "#                             closest_action = nk\n",
    "#                             new_target = q\n",
    "#\n",
    "#                             if dist < tol:\n",
    "#                                 found_action = True\n",
    "#                                 break\n",
    "#\n",
    "#                     if found_action:\n",
    "#                         break\n",
    "#\n",
    "#                 #closest action = edge you want to take\n",
    "#                 #step = go to neighbor node\n",
    "#                 state, reward, terminated, truncated, _ = G.nodes(closest_action) #go to the node that it's at the end of the edge\n",
    "#                 total_rew += reward\n",
    "#                 target = new_target\n",
    "#\n",
    "#         return total_rew\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
